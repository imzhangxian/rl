import numpy as np
import math

TRACK = [
            [-5, -5, -5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0],  # track 1 end with finish line
            [-5, -5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0], 
            [-5, -5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0], 
            [-5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0], 
            [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0], 
            [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0],  
            [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5],  # rect 2
            [-1, -1, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5],  # rect 3, 7 lines 
            [-1, -1, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5],  
            [-1, -1, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5],  
            [-1, -1, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5],  
            [-1, -1, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5],  
            [-1, -1, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5],  
            [-1, -1, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5], 
            [-5, -1, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5],  # rect 4, 8 lines
            [-5, -1, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5], 
            [-5, -1, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5], 
            [-5, -1, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5], 
            [-5, -1, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5], 
            [-5, -1, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5], 
            [-5, -1, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5], 
            [-5, -1, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5], 
            [-5, -5, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5],  # rect 5, 7 lines
            [-5, -5, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5], 
            [-5, -5, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5], 
            [-5, -5, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5], 
            [-5, -5, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5], 
            [-5, -5, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5], 
            [-5, -5, -1, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5], 
            [-5, -5, -5, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5],  # rect 6 from start line
            [-5, -5, -5, -1, -1, -1, -1, -1, -1, -5, -5, -5, -5, -5, -5, -5, -5], 
            [-5, -5, -5,  0,  0,  0,  0,  0,  0, -5, -5, -5, -5, -5, -5, -5, -5], 
        ]
ACTIONS = [[1, 1], [1, 0], [1, -1], [0, 1], [0, 0], [0, -1], [-1, 1], [-1, 0], [-1, -1]]

policies = np.zeros() # same dimension as track
values = np.zeros() # state values
action_values = np.zeros() # action value q(s, a)

def adjust_speed(v, a):
    return None

# generate an episode
def gen_episode():
    # REPEAT:
    # random select a start point
    # initial velocity
    # pick action with policy
    # adjust speed
    # calculate next position
    # break if get finish line
    return None

# policy evaluation w/ Monte Carlo
def policy_eval():
    #REPEAT:
    # generate episode
    # update 
    return None

# policy improvement
